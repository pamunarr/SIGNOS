{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75be647a-ee5c-45c4-9adb-fb8a10efab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bpy\n",
    "import numpy as np\n",
    "from pickle import load\n",
    "from arm_movement import max_left_shoulder_rotation, max_right_shoulder_rotation, landmarks2arm_position, arm_position2landmarks\n",
    "from config import pi\n",
    "from mathutils import Vector, Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9611aa2d-2aa4-4151-bb5b-6c7bb3d12112",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Datos/Procesados/alphabet_landmarks_spread.pkl\", \"rb\") as f:\n",
    "    total_results = load(f)\n",
    "\n",
    "\n",
    "bone_conexions_list = [[0, 1], [0, 2], [0, 3], [3, 4], [4, 5], [4, 6]]\n",
    "bone_names = [\"l_hip\", \"r_hip\", \"d_backbone\", \"u_backbone\", \"l_shoulder\", \"r_shoulder\"]\n",
    "bone_parents_list = [-1, -1, -1, 2, 3, 3]\n",
    "\n",
    "bone_conexions_list.extend([[i, i+2] for i in range(5, 9)])\n",
    "bone_names.extend([\"%s_%s\" % (side, part) for part in [\"upperarm\", \"forearm\"] for side in [\"l\", \"r\"]])\n",
    "bone_parents_list.extend(range(4, 8))\n",
    "\n",
    "bone_conexions_list.extend([[9+side+2*(i!=0)*(4*finger+i), 9+side+2*(4*finger+i+1)] for finger in range(5) for i in range(4) for side in range(2)])\n",
    "bone_names.extend([\"%s_%s_%d\" % (side, finger_name, i)\n",
    "                   for finger_name in [\"thumb\", \"index\", \"middle\", \"ring\", \"pinky\"] for i in range(4) for side in [\"l\", \"r\"]])\n",
    "bone_parents_list.extend([8+side+2*(i!=0)*(4*finger+i) for finger in range(5) for i in range(4) for side in range(2)])\n",
    "\n",
    "bone_conexions = np.array(bone_conexions_list, dtype=np.uint8)\n",
    "bone_parents = np.array(bone_parents_list, dtype=np.int8)\n",
    "\n",
    "\n",
    "trunk_landmarks_avatar = np.array([\n",
    "    [0.15, 0., 0.],\n",
    "    [-0.15, 0., 0.],\n",
    "    [0.2, -0.5, 0.],\n",
    "    [-0.2, -0.5, 0.]\n",
    "], dtype=np.float64)\n",
    "\n",
    "left_finger_directions = np.array([\n",
    "    [[0, -np.sin(0.31*pi), np.cos(0.31*pi)],\n",
    "     [0, -np.sin(0.09*pi), np.cos(0.09*pi)],\n",
    "     [0, -np.sin(0.02*pi), np.cos(0.02*pi)],\n",
    "     [0, np.sin(0.03*pi), np.cos(0.03*pi)],\n",
    "     [0, np.sin(0.11*pi), np.cos(0.11*pi)]],\n",
    "    [[0, -np.sin(0.17*pi), np.cos(0.17*pi)],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1]],\n",
    "    [[0, -np.sin(0.17*pi), np.cos(0.17*pi)],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1]],\n",
    "    [[0, -np.sin(0.17*pi), np.cos(0.17*pi)],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1]]\n",
    "], dtype=np.float64)\n",
    "right_finger_directions = np.array([\n",
    "    [[0, np.sin(0.31*pi), np.cos(0.31*pi)],\n",
    "     [0, np.sin(0.09*pi), np.cos(0.09*pi)],\n",
    "     [0, np.sin(0.02*pi), np.cos(0.02*pi)],\n",
    "     [0, -np.sin(0.03*pi), np.cos(0.03*pi)],\n",
    "     [0, -np.sin(0.11*pi), np.cos(0.11*pi)]],\n",
    "    [[0, np.sin(0.17*pi), np.cos(0.17*pi)],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1]],\n",
    "    [[0, np.sin(0.17*pi), np.cos(0.17*pi)],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1]],\n",
    "    [[0, np.sin(0.17*pi), np.cos(0.17*pi)],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1],\n",
    "     [0, 0, 1]]\n",
    "], dtype=np.float64)\n",
    "left_finger_lengths = np.array([\n",
    "    [0.03, 0.103, 0.103, 0.1, 0.09],\n",
    "    [0.045, 0.031, 0.035, 0.032, 0.025],\n",
    "    [0.032, 0.024, 0.026, 0.023, 0.017],\n",
    "    [0.033, 0.024, 0.025, 0.025, 0.023]\n",
    "], dtype=np.float64).reshape(4, 5, 1)\n",
    "right_finger_lengths = left_finger_lengths.copy()\n",
    "\n",
    "arms_position_rest = {\n",
    "    \"left_shoulder_direction\": np.array([0, 1, 0], dtype=np.float64),\n",
    "    \"left_upperarm_length\": np.float64(0.33),\n",
    "    \"left_shoulder_rotation\": pi/2.,\n",
    "    \"left_elbow_angle\": pi,\n",
    "    \"left_forearm_length\": np.float64(0.27),\n",
    "    \"left_elbow_rotation\": np.float64(0),\n",
    "    \"left_wrist_rotation\": np.float64(0),\n",
    "    \"left_wrist_inclination\": np.float64(0),\n",
    "    \"left_finger_directions\": left_finger_directions,\n",
    "    \"left_finger_lengths\": left_finger_lengths,\n",
    "\n",
    "    \"right_shoulder_direction\": np.array([0, 1, 0], dtype=np.float64),\n",
    "    \"right_upperarm_length\": np.float64(0.33),\n",
    "    \"right_shoulder_rotation\": pi/2.,\n",
    "    \"right_elbow_angle\": pi,\n",
    "    \"right_forearm_length\": np.float64(0.27),\n",
    "    \"right_elbow_rotation\": np.float64(0),\n",
    "    \"right_wrist_rotation\": np.float64(0),\n",
    "    \"right_wrist_inclination\": np.float64(0),\n",
    "    \"right_finger_directions\": right_finger_directions,\n",
    "    \"right_finger_lengths\": right_finger_lengths\n",
    "}\n",
    "\n",
    "half_landmarks_rest = arm_position2landmarks(arms_position_rest, trunk_landmarks_avatar, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9be8566-cdb7-4e94-89ec-7601453e4479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_half_landmarks(data, letter, frame_start, frame_stop=None):\n",
    "    if not frame_stop:\n",
    "        frame_stop = frame_start + 1\n",
    "    half_landmarks = np.empty((frame_stop - frame_start, 48, 3), dtype=np.float64)\n",
    "    half_landmarks[:, :6] = data[letter][\"landmarks\"][\"pose\"][frame_start:frame_stop, [23, 24] + list(range(11, 15)), :-1]\n",
    "    half_landmarks[:, 6::2] = data[letter][\"landmarks\"][\"left_hand\"][frame_start:frame_stop]\n",
    "    half_landmarks[:, 6::2, -1] += data[letter][\"landmarks\"][\"pose\"][frame_start:frame_stop, 15, 2].reshape(-1, 1)\n",
    "    half_landmarks[:, 7::2] = data[letter][\"landmarks\"][\"right_hand\"][frame_start:frame_stop]\n",
    "    half_landmarks[:, 7::2, -1] += data[letter][\"landmarks\"][\"pose\"][frame_start:frame_stop, 16, 2].reshape(-1, 1)\n",
    "    return half_landmarks.squeeze()\n",
    "\n",
    "def get_shoulder_basis(half_landmarks):\n",
    "    shoulder_basis = np.empty((2, 3, 3), dtype=np.float64)\n",
    "\n",
    "    shoulder_basis[0, :, 0] = half_landmarks[2] - half_landmarks[3]\n",
    "    shoulder_basis[0, :, 2] = np.cross(shoulder_basis[0, :, 0], half_landmarks[0] - half_landmarks[2])\n",
    "    shoulder_basis[0, :, 1] = np.cross(shoulder_basis[0, :, 2], shoulder_basis[0, :, 0])\n",
    "\n",
    "    shoulder_basis[1, :, 0] = half_landmarks[3] - half_landmarks[2]\n",
    "    shoulder_basis[1, :, 2] = np.cross(shoulder_basis[1, :, 0], half_landmarks[1] - half_landmarks[3])\n",
    "    shoulder_basis[1, :, 1] = np.cross(shoulder_basis[1, :, 2], shoulder_basis[1, :, 0])\n",
    "\n",
    "    shoulder_basis /= np.linalg.norm(shoulder_basis, axis=1, keepdims=True)\n",
    "    return shoulder_basis\n",
    "\n",
    "def get_hand_basis(half_landmarks):\n",
    "    hand_basis = np.empty((2, 3, 3), dtype=np.float64)\n",
    "\n",
    "    hand_basis[0, :, 0] = np.cross(half_landmarks[40] - half_landmarks[6], half_landmarks[16] - half_landmarks[6])\n",
    "    hand_basis[0, :, 2] = (half_landmarks[40] + half_landmarks[16])/2. - half_landmarks[6]\n",
    "    hand_basis[0, :, 1] = np.cross(hand_basis[0, :, 2], hand_basis[0, :, 0])\n",
    "\n",
    "    hand_basis[1, :, 0] = np.cross(half_landmarks[17] - half_landmarks[7], half_landmarks[41] - half_landmarks[7])\n",
    "    hand_basis[1, :, 2] = (half_landmarks[41] + half_landmarks[17])/2. - half_landmarks[7]\n",
    "    hand_basis[1, :, 1] = np.cross(hand_basis[1, :, 2], hand_basis[1, :, 0])\n",
    "\n",
    "    hand_basis /= np.linalg.norm(hand_basis, axis=1, keepdims=True)\n",
    "    return hand_basis\n",
    "\n",
    "def get_rot_angles_v(v1, v2, v3):\n",
    "    if np.isclose(v2, 1):\n",
    "        beta = 0.\n",
    "        gamma = 0.\n",
    "    else:\n",
    "        if np.isclose(v3*v3, 1):\n",
    "            beta = np.sign(v3) * pi/2.\n",
    "            gamma = 0.\n",
    "        else:\n",
    "            gamma = np.arctan2(-v1, v2)\n",
    "            beta = np.arctan2(v3, -v1/np.sin(gamma)) if np.isclose(v2, 0) else np.arctan2(v3, v2/np.cos(gamma))\n",
    "    return beta, gamma\n",
    "\n",
    "def imaginary_rotation(beta, gamma, bone_matrix, half_landmarks, base_index, side):\n",
    "    rotation_matrix = np.array([\n",
    "        [np.cos(gamma), np.sin(gamma), 0],\n",
    "        [- np.cos(beta) * np.sin(gamma), np.cos(beta) * np.cos(gamma), np.sin(beta)],\n",
    "        [np.sin(beta) * np.sin(gamma), - np.sin(beta) * np.cos(gamma), np.cos(beta)]\n",
    "    ], dtype=np.float64)\n",
    "    bone_matrix_np = np.array(bone_matrix, dtype=np.float64)\n",
    "    moving_vectors = (half_landmarks[2*np.arange(base_index//2 + 1, 24)+side] - half_landmarks[base_index+side])[:, [0, 2, 1]] * np.array([1, 1, -1])\n",
    "\n",
    "    half_landmarks[2*np.arange(base_index//2 + 1, 24)+side] = (moving_vectors @ bone_matrix_np @ rotation_matrix @ bone_matrix_np.T\n",
    "                                                              )[:, [0, 2, 1]] * np.array([1, -1, 1]) + half_landmarks[base_index+side]\n",
    "\n",
    "def get_wrist_rotation_matrix(arms_position, side, inverse):\n",
    "    w = [\"left\", \"right\"][side]\n",
    "    sign = 1 if inverse else -1\n",
    "\n",
    "    a = np.cos(arms_position[\"%s_wrist_inclination\" % w])\n",
    "    b = np.sin(arms_position[\"%s_wrist_inclination\" % w])\n",
    "    c = np.cos(arms_position[\"%s_wrist_rotation\" % w])\n",
    "    d = np.sin(arms_position[\"%s_wrist_rotation\" % w])\n",
    "\n",
    "    return Matrix([\n",
    "        [1.+(a-1.)*c*c, -sign*b*c, (1.-a)*c*d],\n",
    "        [sign*b*c, a, -sign*b*d],\n",
    "        [(1.-a)*c*d, sign*b*d, 1.+(a-1.)*d*d]\n",
    "    ])\n",
    "\n",
    "def get_arms_position(half_landmarks, frame_dimensions, arms_position_base):\n",
    "    arms_position = landmarks2arm_position(half_landmarks, *frame_dimensions)\n",
    "    for k, v in arms_position.items():\n",
    "        if np.isnan(v).any():\n",
    "            arms_position[k] = arms_position_base[k]\n",
    "    return arms_position\n",
    "\n",
    "def isiterable(x):\n",
    "    return \"__iter__\" in dir(x)\n",
    "\n",
    "def is_dynamic_pose(x):\n",
    "    return isiterable(x) and all(map(lambda y : y.shape==(48, 3), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836139fb-8630-410d-bf4b-8ccdd434db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_arms_blender(\n",
    "    armature_filepath, armature_name, half_landmarks_armature, arms_position_armature,\n",
    "    list_half_landmarks, list_frame_dimensions, list_time_movement, list_time_position,\n",
    "    fps, animation_filepath\n",
    "):\n",
    "    # Obtain the armature\n",
    "    bpy.ops.wm.open_mainfile(filepath=armature_filepath)\n",
    "    armature = bpy.data.objects.get(armature_name)\n",
    "    bpy.context.view_layer.objects.active = armature\n",
    "    arms_bones_names = bone_names[6:]\n",
    "\n",
    "    def set_pose(half_world_landmarks_0, arms_position_0, arms_position_1):\n",
    "        half_world_landmarks_ = half_world_landmarks_0.copy()\n",
    "        arms_position_ = arms_position_0.copy()\n",
    "\n",
    "        shoulder_basis = get_shoulder_basis(half_world_landmarks_)\n",
    "\n",
    "        def upperarm_rotation():\n",
    "            for side in range(2):\n",
    "                l = [\"l\", \"r\"][side]\n",
    "                w = [\"left\", \"right\"][side]\n",
    "            \n",
    "                bone_name = \"%s_upperarm\" % l\n",
    "                bone = armature.pose.bones[bone_name]\n",
    "                bone.rotation_mode = 'YXZ'\n",
    "            \n",
    "                upperarm_image = arms_position_1[\"%s_shoulder_direction\" % w] @ shoulder_basis[side].T\n",
    "                v1, v2, v3 = bone.matrix.transposed().to_3x3() @ Vector(upperarm_image[[0, 2, 1]] * np.array([1, 1, -1]))\n",
    "            \n",
    "                beta, gamma = get_rot_angles_v(v1, v2, v3)\n",
    "                if np.isclose(v2, 1):\n",
    "                    alpha = (arms_position_1[\"%s_shoulder_rotation\" % w] - arms_position_[\"%s_shoulder_rotation\" % w]) * (1 - 2*side)\n",
    "                else:\n",
    "                    imaginary_rotation(beta, gamma, bone.matrix.to_3x3(), half_world_landmarks_, 2, side)\n",
    "            \n",
    "                    if np.isclose(arms_position_[\"%s_elbow_angle\" % w], pi):\n",
    "                        aux_position = landmarks2arm_position(half_world_landmarks_, 1, 1)\n",
    "                        shoulder_rotation = (aux_position[\"%s_shoulder_rotation\" % w] +\n",
    "                                             aux_position[\"%s_elbow_rotation\" % w] - arms_position_[\"%s_elbow_rotation\" % w])\n",
    "                        alpha = (arms_position_1[\"%s_shoulder_rotation\" % w] - shoulder_rotation) * (1 - 2*side)\n",
    "                    else:\n",
    "                        alpha = (arms_position_1[\"%s_shoulder_rotation\" % w] -\n",
    "                                 landmarks2arm_position(half_world_landmarks_, 1, 1)[\"%s_shoulder_rotation\" % w]) * (1 - 2*side)\n",
    "                bone.rotation_euler = (beta, alpha, gamma)\n",
    "\n",
    "        def forearm_rotation():\n",
    "            for side in range(2):\n",
    "                l = [\"l\", \"r\"][side]\n",
    "                w = [\"left\", \"right\"][side]\n",
    "\n",
    "                bone_name = \"%s_forearm\" % l\n",
    "                bone = armature.pose.bones[bone_name]\n",
    "                bone.rotation_mode = 'YXZ'\n",
    "\n",
    "                if np.isclose(arms_position_[\"%s_elbow_angle\" % w], arms_position_1[\"%s_elbow_angle\" % w]):\n",
    "                    alpha = (arms_position_1[\"%s_elbow_rotation\" % w] - arms_position_[\"%s_elbow_rotation\" % w]) * (1 - 2*side)\n",
    "                    beta = 0.\n",
    "                    gamma = 0.\n",
    "                else:\n",
    "                    bone_matrix = bone.matrix.to_3x3()\n",
    "\n",
    "                    v2 = (arms_position_[\"%s_shoulder_direction\" % w] @ shoulder_basis[side].T)[[0, 2, 1]] * np.array([1, 1, -1])\n",
    "                    if np.isclose(arms_position_[\"%s_elbow_angle\" % w], pi):\n",
    "                        max_shoulder_rotation = [max_left_shoulder_rotation, max_right_shoulder_rotation][side]\n",
    "                        arm_plane_normal_vector_max_rotation = (max_shoulder_rotation(arms_position_[\"%s_shoulder_direction\" % w]) @\n",
    "                                                                shoulder_basis[side].T)[[0, 2, 1]] * np.array([1, 1, -1])\n",
    "                        aux_vector = np.cross(v2, arm_plane_normal_vector_max_rotation) * (1 - 2*side)\n",
    "                        arm_plane_normal_vector = (np.cos(arms_position_[\"%s_shoulder_rotation\" % w]) * arm_plane_normal_vector_max_rotation +\n",
    "                                                   np.sin(arms_position_[\"%s_shoulder_rotation\" % w]) * aux_vector)\n",
    "                        v1 = - arm_plane_normal_vector\n",
    "                    else:\n",
    "                        forearm_direction = (half_world_landmarks_[6+side] - half_world_landmarks_[4+side])[[0, 2, 1]] * np.array([1, 1, -1])\n",
    "                        forearm_direction /= np.linalg.norm(forearm_direction)\n",
    "                        v1 = np.cross(forearm_direction, v2)\n",
    "                        v1 /= np.linalg.norm(v1)\n",
    "                    v3 = np.cross(v1, v2)\n",
    "                    parent_matrix = Matrix(np.array([v1, v2, v3]).T)\n",
    "\n",
    "                    beta_parent = arms_position_1[\"%s_elbow_angle\" % w] - arms_position_[\"%s_elbow_angle\" % w]\n",
    "                    rotation_matrix_parent = Matrix([\n",
    "                        [1, 0, 0],\n",
    "                        [0, np.cos(beta_parent), - np.sin(beta_parent)],\n",
    "                        [0, np.sin(beta_parent), np.cos(beta_parent)]\n",
    "                    ])\n",
    "                    rotation_matrix_bone = bone_matrix.transposed() @ parent_matrix @ rotation_matrix_parent @ parent_matrix.transposed() @ bone_matrix\n",
    "                    beta, _, gamma = rotation_matrix_bone.to_euler(\"YXZ\")\n",
    "\n",
    "                    imaginary_rotation(beta, gamma, bone_matrix, half_world_landmarks_, 4, side)\n",
    "\n",
    "                    alpha = (arms_position_1[\"%s_elbow_rotation\" % w] -\n",
    "                             landmarks2arm_position(half_world_landmarks_, 1, 1)[\"%s_elbow_rotation\" % w]) * (1 - 2*side)\n",
    "                bone.rotation_euler = (beta, alpha, gamma)\n",
    "\n",
    "        def wrist_rotation():\n",
    "            hand_basis = get_hand_basis(half_world_landmarks_)\n",
    "            for side in range(2):\n",
    "                l = [\"l\", \"r\"][side]\n",
    "                w = [\"left\", \"right\"][side]\n",
    "\n",
    "                forearm_direction = half_world_landmarks_[6+side] - half_world_landmarks_[4+side]\n",
    "                forearm_direction /= np.linalg.norm(forearm_direction)\n",
    "                if np.isclose(arms_position_[\"%s_elbow_angle\" % w], pi):\n",
    "                    max_shoulder_rotation = [max_left_shoulder_rotation, max_right_shoulder_rotation][side]\n",
    "                    arm_rotation = arms_position_[\"%s_shoulder_rotation\" % w] + arms_position_[\"%s_elbow_rotation\" % w] + pi/2.\n",
    "                    aux_vector = max_shoulder_rotation(arms_position_[\"%s_shoulder_direction\" % w]) @ shoulder_basis[side].T\n",
    "                    palm_normal_vector_max_arm_rotation = np.cross(aux_vector, forearm_direction)\n",
    "                    palm_normal_vector_no_wrist_inclination = (np.cos(arm_rotation) * palm_normal_vector_max_arm_rotation +\n",
    "                                                               (1 - 2*side) * np.sin(arm_rotation) * aux_vector)\n",
    "                else:\n",
    "                    palm_normal_vector_no_elbow_rotation = np.cross(arms_position_[\"%s_shoulder_direction\" % w] @ shoulder_basis[side].T,\n",
    "                                                                    forearm_direction) * (1 - 2*side)\n",
    "                    palm_normal_vector_no_elbow_rotation /= np.linalg.norm(palm_normal_vector_no_elbow_rotation)\n",
    "                    aux_vector = np.cross(forearm_direction, palm_normal_vector_no_elbow_rotation)\n",
    "                    palm_normal_vector_no_wrist_inclination = (np.cos(arms_position_[\"%s_elbow_rotation\" % w]) * palm_normal_vector_no_elbow_rotation +\n",
    "                                                               (1 - 2*side) * np.sin(arms_position_[\"%s_elbow_rotation\" % w]) * aux_vector)\n",
    "                v1 = palm_normal_vector_no_wrist_inclination[[0, 2, 1]] * np.array([1, 1, -1])\n",
    "                v3 = forearm_direction[[0, 2, 1]] * np.array([1, 1, -1])\n",
    "                v2 = np.cross(v3, v1)\n",
    "                parent_matrix = Matrix(np.array([v1, v3, -v2]).T)\n",
    "\n",
    "                rotation_matrix_parent_0 = get_wrist_rotation_matrix(arms_position_, side, True)\n",
    "                rotation_matrix_parent_1 = get_wrist_rotation_matrix(arms_position_1, side, False)\n",
    "                rotation_matrix = parent_matrix @ rotation_matrix_parent_1 @ rotation_matrix_parent_0 @ parent_matrix.transposed()\n",
    "\n",
    "                bone_names_ = [\"%s_%s_0\" % (l, finger) for finger in [\"index\", \"middle\", \"ring\", \"pinky\"]]\n",
    "                for bone_name in bone_names_:\n",
    "                    bone = armature.pose.bones[bone_name]\n",
    "                    bone.rotation_mode = 'YXZ'\n",
    "        \n",
    "                    bone_matrix = bone.matrix.to_3x3()\n",
    "                    rotation_matrix_bone = bone_matrix.transposed() @ rotation_matrix @ bone_matrix\n",
    "                    bone.rotation_euler = rotation_matrix_bone.to_euler(\"YXZ\")\n",
    "\n",
    "                bone_name = \"%s_thumb_0\" % l\n",
    "                bone = armature.pose.bones[bone_name]\n",
    "                bone.rotation_mode = 'YXZ'\n",
    "                bone_matrix = bone.matrix.to_3x3()\n",
    "\n",
    "                thumb_0_direction = arms_position_1[\"%s_finger_directions\" % w][0, 0] @ hand_basis[side].T\n",
    "                v1, v2, v3 = bone_matrix.transposed() @ Vector(thumb_0_direction[[0, 2, 1]] * np.array([1, 1, -1]))\n",
    "                beta, gamma = get_rot_angles_v(v1, v2, v3)\n",
    "\n",
    "                rotation_matrix_bone = (bone_matrix.transposed() @ rotation_matrix @ bone_matrix @\n",
    "                                        Matrix().Rotation(gamma, 3, 'Z') @ Matrix().Rotation(beta, 3, 'X'))\n",
    "                bone.rotation_euler = rotation_matrix_bone.to_euler(\"YXZ\")\n",
    "\n",
    "        def update_position(check_arm_extension=False):\n",
    "            bpy.context.view_layer.update()\n",
    "            for bone_number in range(6, 50):\n",
    "                bone = armature.pose.bones[bone_names[bone_number]]\n",
    "                half_world_landmarks_[bone_number-2] = np.array(bone.tail, dtype=np.float64)[[0, 2, 1]] * np.array([1, -1, 1])\n",
    "\n",
    "            if check_arm_extension:\n",
    "                left_arm_is_extended = np.isclose(arms_position_[\"left_elbow_angle\"], pi)\n",
    "                right_arm_is_extended = np.isclose(arms_position_[\"right_elbow_angle\"], pi)\n",
    "                left_elbow_rotation = arms_position_[\"left_elbow_rotation\"]\n",
    "                right_elbow_rotation = arms_position_[\"right_elbow_rotation\"]\n",
    "                arms_position_.update(landmarks2arm_position(half_world_landmarks_, 1, 1))\n",
    "                if left_arm_is_extended:\n",
    "                    arms_position_[\"left_shoulder_rotation\"] = (arms_position_[\"left_shoulder_rotation\"] +\n",
    "                                                                arms_position_[\"left_elbow_rotation\"] - left_elbow_rotation)\n",
    "                    arms_position_[\"left_elbow_rotation\"] = left_elbow_rotation\n",
    "                if right_arm_is_extended:\n",
    "                    arms_position_[\"right_shoulder_rotation\"] = (arms_position_[\"right_shoulder_rotation\"] +\n",
    "                                                                 arms_position_[\"right_elbow_rotation\"] - right_elbow_rotation)\n",
    "                    arms_position_[\"right_elbow_rotation\"] = right_elbow_rotation\n",
    "            else:\n",
    "                arms_position_.update(landmarks2arm_position(half_world_landmarks_, 1, 1))\n",
    "\n",
    "        # Upperarm direction and rotation\n",
    "        upperarm_rotation()\n",
    "        update_position(True)\n",
    "\n",
    "        # Forearm direction and rotation\n",
    "        forearm_rotation()\n",
    "        update_position()\n",
    "\n",
    "        # Wrist rotation and inclination, thumb direction\n",
    "        wrist_rotation()\n",
    "        update_position()\n",
    "\n",
    "        # Fingers\n",
    "        hand_basis = get_hand_basis(half_world_landmarks_)\n",
    "\n",
    "        for phalanx in range(1, 4):\n",
    "            for side in range(2):\n",
    "                l = [\"l\", \"r\"][side]\n",
    "                w = [\"left\", \"right\"][side]\n",
    "\n",
    "                bone_names_ = [\"%s_%s_%d\" % (l, finger, phalanx) for finger in [\"thumb\", \"index\", \"middle\", \"ring\", \"pinky\"]]\n",
    "\n",
    "                finger_directions_image = (arms_position_1[\"%s_finger_directions\" % w][phalanx] @ hand_basis[side].T\n",
    "                                          )[:, [0, 2, 1]] * np.array([1, 1, -1])\n",
    "                for finger in range(5):\n",
    "                    bone = armature.pose.bones[bone_names_[finger]]\n",
    "                    bone.rotation_mode = 'YXZ'\n",
    "                    \n",
    "                    v1, v2, v3 = bone.matrix.transposed().to_3x3() @ Vector(finger_directions_image[finger])\n",
    "                    beta, gamma = get_rot_angles_v(v1, v2, v3)\n",
    "                    bone.rotation_euler = (beta, 0, gamma)\n",
    "            update_position()\n",
    "\n",
    "    def insert_pose(frame):\n",
    "        for bone_name in arms_bones_names:\n",
    "            bone = armature.pose.bones[bone_name]\n",
    "            bone.keyframe_insert(data_path=\"rotation_euler\", frame=frame)\n",
    "\n",
    "    def clear_rotations():\n",
    "        bpy.ops.pose.select_all(action='SELECT')\n",
    "        bpy.ops.pose.rot_clear()\n",
    "\n",
    "    def set_pose_in_interval(half_landmarks, frame_dimensions, T, time_position):\n",
    "        arms_position = get_arms_position(half_landmarks, frame_dimensions, arms_position_armature)\n",
    "        set_pose(half_landmarks_armature, arms_position_armature, arms_position)\n",
    "        insert_pose(int(T*fps)) # Set the pose in the first frame\n",
    "        T += time_position\n",
    "        insert_pose(int(T*fps)) # Set the pose in the last frame\n",
    "        clear_rotations()\n",
    "        return T\n",
    "\n",
    "    def set_dynamic_pose(dynamic_half_landmarks, frame_dimensions, T0):\n",
    "        frame = int(T0*fps)\n",
    "        for half_landmarks in dynamic_half_landmarks:\n",
    "            arms_position = get_arms_position(half_landmarks, frame_dimensions, arms_position_armature)\n",
    "            set_pose(half_landmarks_armature, arms_position_armature, arms_position)\n",
    "            insert_pose(frame)\n",
    "            frame += 1\n",
    "            clear_rotations()\n",
    "        return frame/fps\n",
    "\n",
    "    # Start animation\n",
    "    bpy.ops.object.mode_set(mode='POSE')\n",
    "\n",
    "    assert isiterable(list_half_landmarks), \"`list_half_landmarks` must be an iterable.\"\n",
    "    n_dynamic_positions = sum(map(is_dynamic_pose, list_half_landmarks))\n",
    "\n",
    "    if isinstance(list_time_movement, (int, float)):\n",
    "        list_time_movement = [list_time_movement] * (len(list_half_landmarks) - 1)\n",
    "    else:\n",
    "        assert isiterable(list_time_movement), \"`list_time_movement` must be a number or an iterable.\"\n",
    "        assert len(list_time_movement)==len(list_half_landmarks) - 1, \"`list_time_movement` must have one element less than `list_half_landmarks`.\"\n",
    "\n",
    "    if isinstance(list_time_position, (int, float)):\n",
    "        list_time_position = [list_time_position] * (len(list_half_landmarks) - n_dynamic_positions)\n",
    "    else:\n",
    "        assert isiterable(list_time_position), \"`list_time_position` must be a number or an iterable.\"\n",
    "        error_text = \"`list_time_position` must have as many elements as no-dynamic poses in `list_half_landmarks`.\"\n",
    "        assert len(list_time_position)==len(list_half_landmarks) - n_dynamic_positions, error_text\n",
    "\n",
    "    if isinstance(list_frame_dimensions, tuple):\n",
    "        list_frame_dimensions = [list_frame_dimensions] * len(list_half_landmarks)\n",
    "    else:\n",
    "        assert isiterable(list_frame_dimensions), \"`list_frame_dimensions` must be a number or an iterable.\"\n",
    "        assert len(list_time_position)==len(list_half_landmarks), \"`list_frame_dimensions` must have as many elements as `list_half_landmarks`.\"\n",
    "\n",
    "    T = 0\n",
    "    for half_landmarks in list_half_landmarks:\n",
    "        if is_dynamic_pose(half_landmarks):\n",
    "            T = set_dynamic_pose(half_landmarks, list_frame_dimensions.pop(0), T)\n",
    "        else:\n",
    "            T = set_pose_in_interval(half_landmarks, list_frame_dimensions.pop(0), T, list_time_position.pop(0))\n",
    "    \n",
    "        if list_time_movement:\n",
    "            T += list_time_movement.pop(0)\n",
    "\n",
    "    # End and save animation\n",
    "    bpy.ops.object.mode_set(mode='OBJECT')\n",
    "    bpy.ops.wm.save_as_mainfile(filepath=animation_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "528370df-17f0-4a50-984c-6b57403caed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n"
     ]
    }
   ],
   "source": [
    "letters = [\"A\", \"M\"]\n",
    "half_landmarks_letters = np.empty((2, 48, 3), dtype=np.float64)\n",
    "\n",
    "for i, letter in enumerate(letters):\n",
    "    bpy.ops.wm.open_mainfile(filepath=\"avatar_%s.blend\" % letter)\n",
    "    armature = bpy.data.objects.get(\"Armature\")\n",
    "    bpy.context.view_layer.objects.active = armature\n",
    "    \n",
    "    bpy.ops.object.mode_set(mode='POSE')\n",
    "    \n",
    "    half_landmarks_letters[i, :4] = trunk_landmarks_avatar.copy()\n",
    "    \n",
    "    for bone_number in range(6, 50):\n",
    "        bone = armature.pose.bones[bone_names[bone_number]]\n",
    "        half_landmarks_letters[i, bone_number-2] = np.array(bone.tail, dtype=np.float64)[[0, 2, 1]] * np.array([1, -1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f5f77c5e-a66e-4482-bd0d-9c820578e7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"prueba_dedos_3.blend\"\n"
     ]
    }
   ],
   "source": [
    "move_arms_blender(\n",
    "    \"../Datos/Procesados/avatar_armature.blend\", \"Armature\", half_landmarks_rest, arms_position_rest,\n",
    "    [half_landmarks_rest, half_landmarks_letters[0], half_landmarks_letters[1], half_landmarks_rest],\n",
    "    (1, 1), 1, 0.5, 24, \"prueba_dedos_3.blend\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ed5ae5d4-2d13-47c7-8872-2bb28c42b313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"prueba_dedos_4.blend\"\n"
     ]
    }
   ],
   "source": [
    "letter = 'A'\n",
    "n_frames = total_results[letter]['n_frames']\n",
    "frame_dimensions = (total_results[letter]['frame_width'], total_results[letter]['frame_height'])\n",
    "fps = total_results[letter]['fps']\n",
    "\n",
    "dynamic_half_landmarks = get_half_landmarks(total_results, letter, 0, n_frames)\n",
    "\n",
    "move_arms_blender(\n",
    "    \"../Datos/Procesados/avatar_armature.blend\", \"Armature\", half_landmarks_rest, arms_position_rest,\n",
    "    [dynamic_half_landmarks], frame_dimensions, 1, 0.5, fps, \"prueba_dedos_4.blend\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb9215-1e5a-4b67-88b0-b7a72d3e55b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b39cf5-496e-46f2-b154-950c63e2ef78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab785e8-1ae7-4867-8eb6-f4f9131aec53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "341afaf2-213e-409f-908b-ac30091a7121",
   "metadata": {},
   "source": [
    "## Maksym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e586134-c839-47bb-81b5-ea9a408e3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Datos/Procesados/results_3d/skeleton_uplift.pkl\"\n",
    "\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae655761-454c-45ea-8934-341e0b8492f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['body2d', 'right2d', 'left2d', 'success_right', 'success_left', 'poses_3d_clamped', 'poses_3d_filtered', 'poses_3d', 'body_angles', 'right_angles', 'left_angles', 'body_offsets', 'hand_offsets', 'frames_list', 'video_name'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"A\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0508a50-418e-4491-98e0-2fb6115dc886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_half_landmarks_maksym(data, letter, version, frame_start, frame_stop=None):\n",
    "    if not frame_stop:\n",
    "        frame_stop = frame_start + 1\n",
    "    half_landmarks = np.empty((frame_stop - frame_start, 48, 3), dtype=np.float64)\n",
    "    half_landmarks[:, :6] = data[letter][\"poses_3d\" + version][frame_start:frame_stop, [7, 6, 3, 0, 4, 1]]\n",
    "    half_landmarks[:, 6::2] = np.where(\n",
    "        data[letter]['success_left'][frame_start:frame_stop].reshape(-1, 1, 1),\n",
    "        data[letter][\"poses_3d\" + version][frame_start:frame_stop, 40:], np.nan\n",
    "    )\n",
    "    half_landmarks[:, 7::2] = np.where(\n",
    "        data[letter]['success_right'][frame_start:frame_stop].reshape(-1, 1, 1),\n",
    "        data[letter][\"poses_3d\" + version][frame_start:frame_stop, 19:40], np.nan\n",
    "    )\n",
    "    return half_landmarks.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61a3ed3c-1bd1-4dba-9e3f-f168b23c072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"prueba_maksym_0.blend\"\n",
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"prueba_maksym_filtered_0.blend\"\n",
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"prueba_maksym_clamped_0.blend\"\n"
     ]
    }
   ],
   "source": [
    "for version in [\"\", \"_filtered\", \"_clamped\"]:\n",
    "    move_arms_blender(\n",
    "        \"../Datos/Procesados/avatar_armature.blend\", \"Armature\", half_landmarks_rest, arms_position_rest, [\n",
    "            half_landmarks_rest,\n",
    "            get_half_landmarks_maksym(data, \"A\", version, 27),\n",
    "            get_half_landmarks_maksym(data, \"M\", version, 35),\n",
    "            half_landmarks_rest\n",
    "        ], (1, 1), 1, 0.5, 24, \"prueba_maksym%s_0.blend\" % version\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57032104-7402-4834-b5f2-56a0f8881308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"prueba_maksym_filtered_1.blend\"\n"
     ]
    }
   ],
   "source": [
    "letter = 'A'\n",
    "n_frames = total_results[letter]['n_frames']\n",
    "fps = total_results[letter]['fps']\n",
    "\n",
    "version = \"_filtered\"\n",
    "dynamic_half_landmarks = get_half_landmarks_maksym(data, letter, version, 0, n_frames)\n",
    "\n",
    "move_arms_blender(\n",
    "    \"../Datos/Procesados/avatar_armature.blend\", \"Armature\", half_landmarks_rest, arms_position_rest,\n",
    "    [dynamic_half_landmarks], (1, 1), 1, 0.5, fps, \"prueba_maksym%s_1.blend\" % version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2ab5dff-f31c-4aac-8d29-72bbc0c66e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"abecedario_maksym.blend\"\n",
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"abecedario_maksym_filtered.blend\"\n"
     ]
    }
   ],
   "source": [
    "for version in [\"\", \"_filtered\"]:\n",
    "    list_half_landmarks = [half_landmarks_rest]\n",
    "    with open(\"frame_letras_spread.txt\", 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            datos = line[:-1].split(' ')\n",
    "            letter = datos[0]\n",
    "            frames = map(int, datos[1].split('-'))\n",
    "            list_half_landmarks.append(get_half_landmarks_maksym(data, letter, version, *frames))\n",
    "    list_half_landmarks.append(half_landmarks_rest)\n",
    "    \n",
    "    move_arms_blender(\n",
    "        \"../Datos/Procesados/avatar_armature.blend\", \"Armature\", half_landmarks_rest, arms_position_rest,\n",
    "        list_half_landmarks, (1, 1), 1, 0.5, 24, \"../Datos/Procesados/abecedario_maksym%s.blend\" % version\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4da5ce-004e-46c8-a2f6-deb6185d0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_word(word):\n",
    "    \"\"\"\n",
    "    Given a word using the spanish alphabet, returns a list with the letters of the word.\n",
    "    It includes the letters \"CH\", \"LL\", \"Ñ\" and \"RR\".\n",
    "\n",
    "    Input: word (string)\n",
    "    Output: token_list (list of strings)\n",
    "    \"\"\"\n",
    "    # Define the alphabet\n",
    "    alphabet = [\n",
    "        'A', 'B', 'C', 'CH', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'LL', 'M',\n",
    "        'N', 'Ñ', 'O', 'P', 'Q', 'R', 'RR', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'\n",
    "    ]\n",
    "\n",
    "    # Write the word in capital letters\n",
    "    word = word.upper()\n",
    "\n",
    "    # Verify that all the letters of the word are in the alphabet\n",
    "    if not all(map(lambda char : char in alphabet, word)):\n",
    "        raise Exception(\"Some letter of the word is not in the alphabet.\")\n",
    "\n",
    "    # Initialize the token list\n",
    "    token_list = []\n",
    "    # Go over the word adding tokens to the list\n",
    "    for letter in word:\n",
    "        # If the token is \"CH\", \"LL\" or \"RR\", we have to remove the last letter from the list and add the complete token\n",
    "        if token_list and any([token_list[-1]==\"C\" and letter==\"H\", token_list[-1]==\"L\" and letter==\"L\", token_list[-1]==\"R\" and letter==\"R\"]):\n",
    "            token_list.append(token_list.pop() + letter)\n",
    "        # If the letter is \"Ñ\", add \"N_\"\n",
    "        elif letter==\"Ñ\":\n",
    "            token_list.append(\"N_\")\n",
    "        # Otherwhise, just add the letter\n",
    "        else:\n",
    "            token_list.append(letter)\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8421c2b-b562-4460-8536-40dd6ba0d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_letter = {}\n",
    "with open(\"frame_letras_spread.txt\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        datos = line[:-1].split(' ')\n",
    "        letter = datos[0]\n",
    "        frames = list(map(int, datos[1].split('-')))\n",
    "        frames_letter[letter] = frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cece634c-a7b5-4bdc-9713-a76c52f2ed4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"BUDA.blend\"\n"
     ]
    }
   ],
   "source": [
    "word = \"Buda\"\n",
    "version = \"_filtered\"\n",
    "\n",
    "list_half_landmarks = [half_landmarks_rest]\n",
    "for letter in tokenize_word(word):\n",
    "    frames = frames_letter[letter]\n",
    "    list_half_landmarks.append(get_half_landmarks_maksym(data, letter, version, *frames))\n",
    "list_half_landmarks.append(half_landmarks_rest)\n",
    "\n",
    "move_arms_blender(\n",
    "    \"../Datos/Procesados/avatar_armature.blend\", \"Armature\", half_landmarks_rest, arms_position_rest,\n",
    "    list_half_landmarks, (1, 1), 1, 0.5, 24, \"../Datos/Procesados/%s.blend\" % word\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c982e8ac-9715-4c59-b5d0-fdf9b313fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_word(word, animation_filepath=None, version=\"_filtered\", start_rest=True, end_rest=True,\n",
    "               armature_filepath=\"../Datos/Procesados/avatar_armature.blend\", armature_name=\"Armature\",\n",
    "               half_landmarks_armature=half_landmarks_rest, arms_position_armature=arms_position_rest,\n",
    "               list_frame_dimensions=(1, 1), list_time_movement=1, list_time_position=0.5, fps=24):\n",
    "    list_half_landmarks = []\n",
    "    if start_rest:\n",
    "        list_half_landmarks.append(half_landmarks_rest)\n",
    "    for letter in tokenize_word(word):\n",
    "        frames = frames_letter[letter]\n",
    "        list_half_landmarks.append(get_half_landmarks_maksym(data, letter, version, *frames))\n",
    "    if end_rest:\n",
    "        list_half_landmarks.append(half_landmarks_rest)\n",
    "\n",
    "    if not animation_filepath:\n",
    "        animation_filepath = word + \".blend\"\n",
    "    move_arms_blender(\n",
    "        armature_filepath, armature_name, half_landmarks_armature, arms_position_armature,\n",
    "        list_half_landmarks, list_frame_dimensions, list_time_movement, list_time_position, fps, animation_filepath\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "062a928e-74ee-46f8-a357-0d911fd6ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"LSEAvatar.blend\"\n"
     ]
    }
   ],
   "source": [
    "word = \"LSEAvatar\"\n",
    "spell_word(word, \"../Datos/Procesados/%s.blend\" % word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8618b3-ad04-4d7c-a7f9-ac7b28f799d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2896996-63e2-4c1c-8ca3-984ee0f69d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_half_landmarks_maksym_(word, version, frame_start, frame_stop=None):\n",
    "    word_path = \"../Datos/Procesados/results_3d/palabras/%s.pkl\" % word\n",
    "    with open(word_path, \"rb\") as f:\n",
    "        data = load(f)\n",
    "\n",
    "    if not frame_stop:\n",
    "        frame_stop = frame_start + 1\n",
    "    half_landmarks = np.empty((frame_stop - frame_start, 48, 3), dtype=np.float64)\n",
    "    half_landmarks[:, :6] = data[\"poses_3d\" + version][frame_start:frame_stop, [7, 6, 3, 0, 4, 1]]\n",
    "    half_landmarks[:, 6::2] = np.where(\n",
    "        data[\"success_left\"][frame_start:frame_stop].reshape(-1, 1, 1),\n",
    "        data[\"poses_3d\" + version][frame_start:frame_stop, 40:], np.nan\n",
    "    )\n",
    "    half_landmarks[:, 7::2] = np.where(\n",
    "        data[\"success_right\"][frame_start:frame_stop].reshape(-1, 1, 1),\n",
    "        data[\"poses_3d\" + version][frame_start:frame_stop, 19:40], np.nan\n",
    "    )\n",
    "    return half_landmarks.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9783a05-ca1d-444b-b7fd-c1a3b0adb8d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.12122495,  0.43434429,  0.04766441],\n",
       "        [-0.12279617,  0.43463343,  0.04046293],\n",
       "        [ 0.15848662,  0.00464481,  0.00537007],\n",
       "        ...,\n",
       "        [-0.01623867,  0.13297957, -0.13475221],\n",
       "        [        nan,         nan,         nan],\n",
       "        [-0.02025601,  0.1335175 , -0.14525039]],\n",
       "\n",
       "       [[ 0.12050183,  0.43396133,  0.04386024],\n",
       "        [-0.12382933,  0.43342209,  0.03972945],\n",
       "        [ 0.159097  ,  0.00629541,  0.00539265],\n",
       "        ...,\n",
       "        [-0.01555347,  0.12989993, -0.12501153],\n",
       "        [        nan,         nan,         nan],\n",
       "        [-0.01857008,  0.12898245, -0.13581423]],\n",
       "\n",
       "       [[ 0.11970007,  0.43434352,  0.03962978],\n",
       "        [-0.1241948 ,  0.43323243,  0.0379243 ],\n",
       "        [ 0.15904707,  0.00764481,  0.00539296],\n",
       "        ...,\n",
       "        [-0.0149905 ,  0.12488312, -0.12394083],\n",
       "        [        nan,         nan,         nan],\n",
       "        [-0.01775838,  0.12341198, -0.13474892]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.1187886 ,  0.43215039,  0.02176938],\n",
       "        [-0.12352364,  0.43080017,  0.02217438],\n",
       "        [ 0.1581616 ,  0.00892776,  0.01167388],\n",
       "        ...,\n",
       "        [-0.01607539,  0.14321369, -0.11336803],\n",
       "        [        nan,         nan,         nan],\n",
       "        [-0.02044659,  0.13925754, -0.12295353]],\n",
       "\n",
       "       [[ 0.11882227,  0.43224335,  0.02173791],\n",
       "        [-0.12348542,  0.43091941,  0.02203118],\n",
       "        [ 0.15814126,  0.00895212,  0.01167248],\n",
       "        ...,\n",
       "        [-0.01547629,  0.14191476, -0.11317228],\n",
       "        [        nan,         nan,         nan],\n",
       "        [-0.0198634 ,  0.13833675, -0.12289809]],\n",
       "\n",
       "       [[ 0.11895538,  0.43204644,  0.02180519],\n",
       "        [-0.12353254,  0.43075296,  0.02194536],\n",
       "        [ 0.15823519,  0.00902246,  0.01167238],\n",
       "        ...,\n",
       "        [-0.01856003,  0.14167948, -0.11118037],\n",
       "        [        nan,         nan,         nan],\n",
       "        [-0.02170738,  0.13824072, -0.12142289]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_half_landmarks_maksym_('yo', \"_filtered\", 20, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2c023dc-a179-4166-a4a2-b488e5bf2148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True]],\n",
       "\n",
       "       [[False]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([True, False]).reshape(2, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d790cdd-a6bf-4c6c-9ca0-c5390921ccda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  1.,  1.,  1.],\n",
       "        [ 2.,  2.,  2.,  2.],\n",
       "        [ 6.,  6.,  6.,  6.]],\n",
       "\n",
       "       [[nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array([True, False]).reshape(2, 1, 1), [[[1, 1, 1, 1], [2, 2, 2, 2], [6, 6, 6, 6]],[[3, 3, 3, 3], [4, 4, 4, 4], [5, 5, 5, 5]]], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1dc91c7-367d-45ba-8af3-ddebbbb9d3f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.04937904e-01,  4.44130361e-01,  1.24356961e-02],\n",
       "        [-1.31747127e-01,  4.37102258e-01, -1.63706299e-03],\n",
       "        [ 1.56001806e-01,  3.00845318e-03, -2.23334224e-04],\n",
       "        ...,\n",
       "        [-1.29865259e-02, -5.06719202e-03, -2.24795729e-01],\n",
       "        [ 5.10655157e-02,  2.37029716e-01, -2.14582860e-01],\n",
       "        [-1.64064392e-02,  6.19643554e-03, -2.18171015e-01]],\n",
       "\n",
       "       [[ 1.04165643e-01,  4.45460320e-01,  2.05338374e-02],\n",
       "        [-1.33237302e-01,  4.38124895e-01, -1.17927883e-03],\n",
       "        [ 1.55706450e-01,  3.00275721e-03,  4.35594236e-04],\n",
       "        ...,\n",
       "        [-8.95620883e-03, -8.91301781e-03, -2.32324153e-01],\n",
       "        [ 4.64888737e-02,  2.11315289e-01, -2.39309564e-01],\n",
       "        [-1.50756761e-02,  1.75062567e-03, -2.26730332e-01]],\n",
       "\n",
       "       [[ 1.01206586e-01,  4.44956571e-01,  2.50029769e-02],\n",
       "        [-1.37445018e-01,  4.35837179e-01, -3.01512145e-03],\n",
       "        [ 1.56692579e-01,  2.80888844e-03,  4.38341900e-04],\n",
       "        ...,\n",
       "        [-5.42514026e-03, -9.50349122e-03, -2.46503130e-01],\n",
       "        [ 3.93925011e-02,  1.87963933e-01, -2.58085907e-01],\n",
       "        [-1.14257708e-02,  1.21913850e-03, -2.40893349e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.08765125e-01,  4.41814780e-01,  3.15940753e-02],\n",
       "        [-1.33972764e-01,  4.35573459e-01,  1.88517701e-02],\n",
       "        [ 1.59908488e-01,  8.96760728e-04, -5.43413358e-03],\n",
       "        ...,\n",
       "        [ 1.93845332e-02,  1.59907222e-01, -2.98062146e-01],\n",
       "        [ 3.44366767e-02,  1.70860663e-01, -2.45649502e-01],\n",
       "        [ 3.28284651e-02,  1.58874348e-01, -2.98865914e-01]],\n",
       "\n",
       "       [[ 1.08914033e-01,  4.41711694e-01,  3.17751430e-02],\n",
       "        [-1.33866772e-01,  4.35554832e-01,  1.87829919e-02],\n",
       "        [ 1.59998715e-01,  9.51245951e-04, -5.50375925e-03],\n",
       "        ...,\n",
       "        [ 1.76090077e-02,  1.61072552e-01, -3.00017893e-01],\n",
       "        [ 3.40741724e-02,  1.70983478e-01, -2.45282277e-01],\n",
       "        [ 3.10256630e-02,  1.60269663e-01, -3.01359773e-01]],\n",
       "\n",
       "       [[ 1.08978599e-01,  4.41586196e-01,  3.18708494e-02],\n",
       "        [-1.33798018e-01,  4.35476184e-01,  1.86822154e-02],\n",
       "        [ 1.59998208e-01,  9.57375218e-04, -5.63209224e-03],\n",
       "        ...,\n",
       "        [ 1.58804283e-02,  1.60641193e-01, -3.01381826e-01],\n",
       "        [ 3.32116075e-02,  1.71069965e-01, -2.44560227e-01],\n",
       "        [ 2.92519256e-02,  1.60102949e-01, -3.03216279e-01]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_half_landmarks_maksym_('nombre', \"_filtered\", 22, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ecf71c3-fccc-4ef1-8f82-3bcebb29483e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"me_llamo_LSEAvatar_3.blend\"\n"
     ]
    }
   ],
   "source": [
    "version = \"_filtered\"\n",
    "armature_filepath=\"../Datos/Procesados/avatar_armature.blend\"\n",
    "armature_name=\"Armature\"\n",
    "half_landmarks_armature=half_landmarks_rest\n",
    "arms_position_armature=arms_position_rest\n",
    "list_frame_dimensions=(1, 1)\n",
    "# list_time_movement=1\n",
    "# list_time_position=0.5\n",
    "fps=24\n",
    "\n",
    "list_half_landmarks = []\n",
    "list_time_position = []\n",
    "list_time_movement = []\n",
    "\n",
    "list_half_landmarks.append(half_landmarks_rest)\n",
    "list_time_position.append(0.5)\n",
    "list_time_movement.append(1)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('yo', version, 20, 35))\n",
    "list_time_movement.append(0.75)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('nombre', version, 24))\n",
    "list_time_position.append(0.25)\n",
    "list_time_movement.append(0.5)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('nombre', version, 40))\n",
    "list_time_position.append(0.25)\n",
    "list_time_movement.append(1)\n",
    "\n",
    "for letter in tokenize_word('LSEAvatar'):\n",
    "    frames = frames_letter[letter]\n",
    "    list_half_landmarks.append(get_half_landmarks_maksym(data, letter, version, *frames))\n",
    "    if len(frames)==1:\n",
    "        list_time_position.append(0.75)\n",
    "    list_time_movement.append(0.75)\n",
    "\n",
    "list_half_landmarks.append(half_landmarks_rest)\n",
    "list_time_position.append(0.5)\n",
    "\n",
    "animation_filepath = \"me_llamo_LSEAvatar_3.blend\"\n",
    "move_arms_blender(\n",
    "    armature_filepath, armature_name, half_landmarks_armature, arms_position_armature,\n",
    "    list_half_landmarks, list_frame_dimensions, list_time_movement, list_time_position, fps, animation_filepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e128de02-e41c-4a06-85d4-16cb99f6438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"gracias_adios_1.blend\"\n"
     ]
    }
   ],
   "source": [
    "version = \"_filtered\"\n",
    "armature_filepath=\"../Datos/Procesados/avatar_armature.blend\"\n",
    "armature_name=\"Armature\"\n",
    "half_landmarks_armature=half_landmarks_rest\n",
    "arms_position_armature=arms_position_rest\n",
    "list_frame_dimensions=(1, 1)\n",
    "# list_time_movement=1\n",
    "# list_time_position=0.5\n",
    "fps=24\n",
    "\n",
    "list_half_landmarks = []\n",
    "list_time_position = []\n",
    "list_time_movement = []\n",
    "\n",
    "list_half_landmarks.append(half_landmarks_rest)\n",
    "list_time_position.append(0.5)\n",
    "list_time_movement.append(1)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('gracias', version, 20, 35))\n",
    "list_time_movement.append(0.75)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('adios', version, 21, 43))\n",
    "list_time_movement.append(0.75)\n",
    "\n",
    "list_half_landmarks.append(half_landmarks_rest)\n",
    "list_time_position.append(0.5)\n",
    "\n",
    "animation_filepath = \"gracias_adios_1.blend\"\n",
    "move_arms_blender(\n",
    "    armature_filepath, armature_name, half_landmarks_armature, arms_position_armature,\n",
    "    list_half_landmarks, list_frame_dimensions, list_time_movement, list_time_position, fps, animation_filepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67d3b69d-fb3c-4c97-8925-f97637c56d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"video_Ceuta_4.blend\"\n"
     ]
    }
   ],
   "source": [
    "version = \"_filtered\"\n",
    "armature_filepath=\"../Datos/Procesados/avatar_armature.blend\"\n",
    "armature_name=\"Armature\"\n",
    "half_landmarks_armature=half_landmarks_rest\n",
    "arms_position_armature=arms_position_rest\n",
    "list_frame_dimensions=(1, 1)\n",
    "# list_time_movement=1\n",
    "# list_time_position=0.5\n",
    "fps=24\n",
    "\n",
    "list_half_landmarks = []\n",
    "list_time_position = []\n",
    "list_time_movement = []\n",
    "\n",
    "list_half_landmarks.append(half_landmarks_rest)\n",
    "list_time_position.append(0.5)\n",
    "list_time_movement.append(1)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('bien', version, 12))\n",
    "list_time_position.append(0.2)\n",
    "list_time_movement.append(0.4)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('buenosdias', version, 34))\n",
    "list_time_position.append(0.2)\n",
    "list_time_movement.append(0.5)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('buenosdias', version, 44))\n",
    "list_time_position.append(0.2)\n",
    "list_time_movement.append(0.5)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('buenosdias', version, 59))\n",
    "list_time_position.append(0.2)\n",
    "list_time_movement.append(0.75)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('ceuta', version, 14))\n",
    "list_time_position.append(0.2)\n",
    "list_time_movement.append(0.5)\n",
    "\n",
    "# list_half_landmarks.append(get_half_landmarks_maksym_('ceuta', version, 21))\n",
    "# list_time_position.append(0.1)\n",
    "# list_time_movement.append(0.25)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('ceuta', version, 25))\n",
    "list_time_position.append(0.2)\n",
    "list_time_movement.append(1)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('yo', version, 20, 35))\n",
    "list_time_movement.append(0.75)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('nombre', version, 24))\n",
    "list_time_position.append(0.25)\n",
    "list_time_movement.append(0.5)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('nombre', version, 40))\n",
    "list_time_position.append(0.25)\n",
    "list_time_movement.append(1)\n",
    "\n",
    "for letter in tokenize_word('LSEAvatar'):\n",
    "    frames = frames_letter[letter]\n",
    "    list_half_landmarks.append(get_half_landmarks_maksym(data, letter, version, *frames))\n",
    "    if len(frames)==1:\n",
    "        list_time_position.append(0.75)\n",
    "    list_time_movement.append(0.75)\n",
    "\n",
    "list_half_landmarks.append(half_landmarks_rest)\n",
    "list_time_position.append(0.5)\n",
    "\n",
    "animation_filepath = \"video_Ceuta_4.blend\"\n",
    "move_arms_blender(\n",
    "    armature_filepath, armature_name, half_landmarks_armature, arms_position_armature,\n",
    "    list_half_landmarks, list_frame_dimensions, list_time_movement, list_time_position, fps, animation_filepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38cd74c5-c332-41a8-859a-ce5f196fb948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (403.34), expect loss of data!\n",
      "Info: Saved \"video_Ceuta_13.blend\"\n"
     ]
    }
   ],
   "source": [
    "version = \"_filtered\"\n",
    "armature_filepath=\"../Datos/Procesados/avatar_armature.blend\"\n",
    "armature_name=\"Armature\"\n",
    "half_landmarks_armature=half_landmarks_rest\n",
    "arms_position_armature=arms_position_rest\n",
    "list_frame_dimensions=(1, 1)\n",
    "# list_time_movement=1\n",
    "# list_time_position=0.5\n",
    "fps=24\n",
    "\n",
    "list_half_landmarks = []\n",
    "list_time_position = []\n",
    "list_time_movement = []\n",
    "\n",
    "list_half_landmarks.append(half_landmarks_rest)\n",
    "list_time_position.append(0.5)\n",
    "list_time_movement.append(1)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('hola', version, 18))\n",
    "list_time_position.append(0.1)\n",
    "list_time_movement.append(0.18)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('hola', version, 23))\n",
    "list_time_position.append(0.05)\n",
    "list_time_movement.append(0.15)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('hola', version, 27))\n",
    "list_time_position.append(0.05)\n",
    "list_time_movement.append(0.1)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('hola', version, 30))\n",
    "list_time_position.append(0.05)\n",
    "list_time_movement.append(0.15)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('hola', version, 34))\n",
    "list_time_position.append(0.1)\n",
    "list_time_movement.append(0.5)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('ceuta', version, 14))\n",
    "list_time_position.append(0.2)\n",
    "list_time_movement.append(0.5)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('ceuta', version, 25))\n",
    "list_time_position.append(0.2)\n",
    "list_time_movement.append(1)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('yo', version, 20, 35))\n",
    "list_time_movement.append(0.75)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('nombre', version, 24))\n",
    "list_time_position.append(0.25)\n",
    "list_time_movement.append(0.5)\n",
    "\n",
    "list_half_landmarks.append(get_half_landmarks_maksym_('nombre', version, 40))\n",
    "list_time_position.append(0.25)\n",
    "list_time_movement.append(1)\n",
    "\n",
    "for letter in tokenize_word('LSEAvatar'):\n",
    "    frames = frames_letter[letter]\n",
    "    list_half_landmarks.append(get_half_landmarks_maksym(data, letter, version, *frames))\n",
    "    if len(frames)==1:\n",
    "        list_time_position.append(0.75)\n",
    "    list_time_movement.append(0.75)\n",
    "\n",
    "list_half_landmarks.append(half_landmarks_rest)\n",
    "list_time_position.append(0.5)\n",
    "\n",
    "animation_filepath = \"video_Ceuta_13.blend\"\n",
    "move_arms_blender(\n",
    "    armature_filepath, armature_name, half_landmarks_armature, arms_position_armature,\n",
    "    list_half_landmarks, list_frame_dimensions, list_time_movement, list_time_position, fps, animation_filepath\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
